run:
  project: "mouse"
  samples: samples.tsv
  units: units.tsv
  gatk: "gatk"
  pipeline: "wgs"

tools:
  crg2: " /hpf/largeprojects/ccmbio/mcouse/dmalkin/mouse_WES/crg2"
  orad: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/crg2-non-conda-tools/orad_2_6_1/orad" 

ref:
  name: GRCm38
  genome: "/hpf/largeprojects/ccmbio/mcouse/dmalkin/mouse_WES/data/genome/GRCm38.p4.genome.fa"
  canon_bed: "/hpf/largeprojects/ccmbio/mcouse/dmalkin/mouse_WES/data/genome/mm10_canon_chr.txt"
  known-variants: "/hpf/largeprojects/ccmbio/mcouse/dmalkin/mouse_WES/data/dbSNP/mgp.v5.merged.dbSNP142.normed.chr.reheader.vcf.gz"
  orad_ref: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/crg2-non-conda-tools/orad_2_6_1/oradata"
  ref_cache: ""

filtering:
  vqsr: false
  hard:
    # hard filtering as outlined in GATK docs
    # (https://gatkforums.broadinstitute.org/gatk/discussion/2806/howto-apply-hard-filters-to-a-call-set)
    snvs:
      "QD < 2.0 || FS > 60.0 || MQ < 30.0 || MQRankSum < -12.5 || ReadPosRankSum < -8.0"
    indels:
      "QD < 2.0 || FS > 200.0 || ReadPosRankSum < -20.0"
  soft:
    platypus:
      name: 'PlatQualDepth'
      filter: '(FR[0] <= 0.5 && TC < 4 && %QUAL < 20) || (TC < 13 && %QUAL < 10) || (FR[0] > 0.5 && TC < 4 && %QUAL < 50)'
    freebayes:
      name: 'FBQualDepth'
      filter: '(AF[0] <= 0.5 && (max(FORMAT/DP) < 4 || (max(FORMAT/DP) < 13 && %QUAL < 10))) || (AF[0] > 0.5 && (max(FORMAT/DP) < 4 && %QUAL < 50))'
    samtools:
      name: 'stQualDepth'
      filter: '((AC[0] / AN) <= 0.5 && max(FORMAT/DP) < 4 && %QUAL < 20) || (max(FORMAT/DP) < 13 && %QUAL < 10) || ((AC[0] / AN) > 0.5 && max(format/DP) < 4 && %QUAL < 50)'
    gatk:
      snvs:
        name: 'GATKCutoffSNP'
        filter: 'TYPE="snp" && (MQRankSum < -12.5 || ReadPosRankSum < -8.0 || QD < 2.0 || FS > 60.0 || MQ < 30.0)'
      indel:
        name: 'GATKCutoffIndel'
        filter: 'TYPE="indel" && (ReadPosRankSum < -20.0 || QD < 2.0 || FS > 200.0 || SOR > 10.0)'


processing:
  mark-duplicates: true
  # Uncomment and point to a bed file with, e.g., captured regions if necessary,
  # see https://gatkforums.broadinstitute.org/gatk/discussion/4133/when-should-i-use-l-to-pass-in-a-list-of-intervals.
  # restrict-regions: captured_regions.bed
  # If regions are restricted, uncomment this to enlarge them by the given value in order to include
  # flanking areas.
  # region-padding: 100

qc:
  fastq_screen:
    conf: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/qc/FastQ_Screen_Genomes/fastq_screen.conf"
  
annotation:
  vep:
    dir: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/snakemake/9db6af70/share/ensembl-vep-113.3-1/"
    dir_cache: "/hpf/largeprojects/ccmbio/mcouse/dmalkin/mouse_WES/data/genome/vep_cache_GRCm38/"

params:
  bwa:
    verbosity: "-v 1"
    markSplitReads: "-M"
    maxMem: ""
  gatk:
    java_opts: "-Xms500m -Xmx9555m -Dsamjdk.compression_level=5"
    HaplotypeCaller: ""
    BaseRecalibrator: ""
    #BaseRecalibrator: "--interval-set-rule INTERSECTION -U LENIENT-VCF-PROCESSING --read-filter BadCigar --read-filter NotzPrimaryAlignment"
    GenotypeGVCFs: ""
    VariantRecalibrator: ""
    Mutect2: 
      gnomad_germline: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/annotation/Mutect2/af-only-gnomad.raw.sites.vcf"
    FilterMutectCalls: ""
  gatk3:
    java_opts: "-Xms500m -Xmx9555m"
    HaplotypeCaller: "-drf DuplicateRead --interval_set_rule INTERSECTION --pair_hmm_implementation VECTOR_LOGLESS_CACHING -ploidy 2 -U LENIENT_VCF_PROCESSING --read_filter BadCigar --read_filter NotPrimaryAlignment"
    annotation: "MappingQualityRankSumTest MappingQualityZero QualByDepth ReadPosRankSumTest RMSMappingQuality BaseQualityRankSumTest FisherStrand GCContent HaplotypeScore HomopolymerRun DepthPerAlleleBySample Coverage ClippingRankSumTest DepthPerSampleHC"
    RealignerTargetCreator: " -l INFO --interval_set_rule INTERSECTION -U LENIENT_VCF_PROCESSING --read_filter BadCigar --read_filter NotPrimaryAlignment "
    IndelRealigner: " -U LENIENT_VCF_PROCESSING --read_filter BadCigar --read_filter NotPrimaryAlignment "
    BaseRecalibrator: " --interval_set_rule INTERSECTION -U LENIENT_VCF_PROCESSING --read_filter BadCigar --read_filter NotPrimaryAlignment "
    PrintReads: " -jdk_deflater -jdk_inflater -U LENIENT_VCF_PROCESSING --read_filter BadCigar --read_filter NotPrimaryAlignment "
  picard:
    MarkDuplicates: "REMOVE_DUPLICATES=false"
    ValidationStringency: "VALIDATION_STRINGENCY=SILENT"
    AssumeSortOrder: "ASSUME_SORT_ORDER=coordinate"
    java_opts: "-Xmx2g"
  qualimap:
    mem: "60G"
    nw: 400
    c: "-c"
    hm: 3
    gtf: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/annotation/exons/hg19_UCSC_exons_canonical_placeholder.bed"
    extra: ""
  verifybamid2:
    svd_prefix: "1000g.phase3 100k b37"
    # --DisableSanityCheck ensures verifybamid2 does not fail for exomes with < 10,000 markers
    extra: "--DisableSanityCheck"
  multiqc:
    config: "~/crg2/rules/multiqc_config.yaml"
  snpeff:
    java_opts: "-Xms750m -Xmx20g"
  svscore:
    operations: "max,sum,top5,top10,mean"
  samtools:
    mpileup: " -t DP -t AD -u -g "
  bcftools:
    mpileup: "-a DP -a AD "
    call: " -m -v "
    # -F x sets the output filter to PASS if any of the variant filters is PASS in sample VCFs to be merged
    merge: "-F x"
  freebayes:
    call: " --genotype-qualities --strict-vcf --ploidy 2 --no-partial-observations --min-repeat-entropy 1 "
  platypus: "--filterDuplicates=0"
  rtg-tools:
    java_opts: "-Xmx20g"
    vcfeval:
      sdf: "/hpf/largeprojects/ccm_dccforge/dccdipg/Common/rtg-tools/GRch37_SDF/"
    vcfsubset:
      java_opts: "-Xmx2048m"
